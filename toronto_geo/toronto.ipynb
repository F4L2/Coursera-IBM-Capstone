{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open the source page from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = requests.get(\"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\").text\n",
    "source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve the table\n",
    "it's the first table of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup( source, 'lxml')\n",
    "table = soup.find(\"table\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_body = table.tbody\n",
    "\n",
    "data = []\n",
    "rows = table_body.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we refine that table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete rows with NA burough  \n",
    "find neighbors for each burough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[0]\n",
    "\n",
    "burough_neigh = {}\n",
    "for d in data:\n",
    "    #borough not assigned \n",
    "    if d[1] == 'Not assigned':\n",
    "        continue\n",
    "    if d[1] not in burough_neigh:\n",
    "        burough_neigh[d[1]] = []\n",
    "    else:\n",
    "        burough_neigh[d[1]].append(d[2])\n",
    "\n",
    "burough_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = { }\n",
    "\n",
    "for d in data:\n",
    "    post = d[0]\n",
    "    bur = d[1]\n",
    "    neigh = d[2]\n",
    "    \n",
    "    if d[1] == 'Not assigned':\n",
    "        continue\n",
    "    \n",
    "    if d[2] is 'Not assigned':\n",
    "        neigh = burough_neigh[d[1]]\n",
    "    \n",
    "    if post not in reduced_data:\n",
    "        reduced_data[post] = { 'bor': [], 'nei': [] }\n",
    "    \n",
    "    if bur not in reduced_data[post]['bor']:\n",
    "        reduced_data[post]['bor'].append(bur)\n",
    "    if neigh not in reduced_data[post]['nei']:\n",
    "        reduced_data[post]['nei'].append(neigh)\n",
    "\n",
    "reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data = { \"Postal Code\": [], 'Borough': [], 'Neighborhood' :[]}\n",
    "\n",
    "for k,v in reduced_data.items():\n",
    "    post = k\n",
    "    bur = v['bor']\n",
    "    neigh = v['nei']\n",
    "    \n",
    "    if neigh is 'Not assigned':\n",
    "        neigh = burough_neigh[bur]\n",
    "    \n",
    "    refined_data[\"Postal Code\"].append(post)\n",
    "    refined_data[\"Borough\"].append(bur[0])\n",
    "    refined_data[\"Neighborhood\"].append(neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we create the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(refined_data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geolocalisation\n",
    "Since we're given a csv file for that, we'll just use it. Quicker, simplier and more precise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = \"Geospatial_Coordinates.csv\"\n",
    "\n",
    "geo_df = pd.read_csv(geo)\n",
    "print(geo_df.shape)\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_df = pd.merge(df,geo_df, on=\"Postal Code\")\n",
    "print(extended_df.shape)\n",
    "extended_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "First we define the limits,\n",
    "we'll take the extremes and add a little distance to the borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "\n",
    "latitude = geo_df[\"Latitude\"]\n",
    "longitude = geo_df[\"Longitude\"]\n",
    "data_points = [ np.array([i,j]) for i,j in zip(latitude, longitude)]\n",
    "\n",
    "\n",
    "extension = 0.005\n",
    "l_min = min(latitude) - extension\n",
    "l_max = max(latitude) + extension\n",
    "L_min = min(longitude) - extension\n",
    "L_max = max(longitude) + extension\n",
    "\n",
    "l_min, l_max, L_min, L_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function to generate initial centroids randomly\n",
    "using the limits set previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_init(l_min, l_max, L_min, L_max, k):\n",
    "    l_rand = np.random.uniform(l_min, l_max, k)\n",
    "    L_rand = np.random.uniform(L_min, L_max, k)\n",
    "\n",
    "    rand_start = [ np.array([i,j]) for i,j in zip(l_rand,L_rand)]\n",
    "    return rand_start\n",
    "\n",
    "rand_init(l_min, l_max, L_min, L_max, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start clustering  \n",
    "So we'll start by initializing random centroid and creating a distance matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance( pointA, pointB ):\n",
    "    return np.linalg.norm( (pointA-pointB) )\n",
    "\n",
    "def cluster_score(cluster, centroid):\n",
    "    sum_score = 0\n",
    "    for point in cluster:\n",
    "        sum_score += distance( point, centroid )\n",
    "    return sum_score\n",
    "\n",
    "def get_score( clusters, centroids ):\n",
    "    score = 0\n",
    "    for clus,cent in zip(clusters, centroids):\n",
    "        score += cluster_score(clus, cent)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i take k = 4, but really there's no particular reasoning behind it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "centroids = rand_init(l_min, l_max, L_min, L_max, k)\n",
    "\n",
    "def get_distance_matrix(data_points, centroids, k):\n",
    "    distance_mat = np.zeros( (len(data_points), k) )\n",
    "    for i in range(len(data_points)): \n",
    "        for j in range(len(centroids)):\n",
    "            dist = distance(data_points[i], centroids[j])\n",
    "            distance_mat[i][j] = dist\n",
    "            \n",
    "    return distance_mat\n",
    "        \n",
    "distance_mat = get_distance_matrix(data_points, centroids, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever a centroid is the closest to a given data point, we set that data point as part of the cluster categorized by that centroid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterize( data_points, distance_mat, k):  \n",
    "    clusters = [ [] for n in range(k)]\n",
    "    for i in range(len(data_points)):\n",
    "        d = distance_mat[i]\n",
    "        ind = np.argmin(d)\n",
    "        c_size.append(ind)\n",
    "        clusters[ind].append(data_points[i])\n",
    "    return clusters\n",
    "    \n",
    "clusters = clusterize(data_points, distance_mat, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "colors = np.random.rand(k,3)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "#plt.scatter( latitude, longitude )\n",
    "plt.scatter( [x[0] for x in centroids], [y[1] for y in centroids], c= colors, marker = 's', s=80)\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    plt.scatter( [x[0] for x in clusters[i]], [y[1] for y in clusters[i]], c= [colors[i]]*len(clusters[i]))\n",
    "    \n",
    "\n",
    "score = get_score(clusters, centroids)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll move the centroid to the mean of their respective clusters and recalculate a new score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recenter_centroids(clusters, centroids):\n",
    "    for i in range(len(centroids)):\n",
    "        if(len(clusters[i]) == 0):\n",
    "            continue\n",
    "        m_lat = np.array([x[0] for x in clusters[i]]).mean()\n",
    "        m_lon = np.array([y[1] for y in clusters[i]]).mean()\n",
    "        centroids[i] = np.array( [m_lat,m_lon] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recenter_centroids(clusters, centroids)\n",
    "        \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter( [x[0] for x in centroids], [y[1] for y in centroids], c= colors, marker = 's', s=100)\n",
    "for i in range(len(clusters)):\n",
    "    plt.scatter( [x[0] for x in clusters[i]], [y[1] for y in clusters[i]], c= [colors[i]]*len(clusters[i]), marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll keep doing that until the change in score is either not significant, worse or doesn't change.  \n",
    "We'll still set an iteration limit at 10000 to prevent it to take too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_until_good(score, centroids, data_points, k):\n",
    "    for it in range(10000):\n",
    "        distance_matrix = get_distance_matrix(data_points, centroids,k)\n",
    "        clusters = clusterize(data_points, distance_matrix, k)\n",
    "        new_score = get_score(clusters, centroids)\n",
    "        difference = score - new_score\n",
    "        if difference < 0: #worse score\n",
    "            break\n",
    "        elif difference < eps: # not significant\n",
    "            break \n",
    "        else:\n",
    "            score = new_score\n",
    "        recenter_centroids(clusters, centroids)\n",
    "    \n",
    "    return centroids, clusters, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "\n",
    "centroids, clusters, score = repeat_until_good(score, centroids, data_points, k)\n",
    "    \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter( [x[0] for x in centroids], [y[1] for y in centroids], c= colors, marker = 's', s=100)\n",
    "for i in range(len(clusters)):\n",
    "    plt.scatter( [x[0] for x in clusters[i]], [y[1] for y in clusters[i]], c= [colors[i]]*len(clusters[i]), marker='.')\n",
    "    \n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll repeat the entire process multiple times to diminish the initialization bias.  \n",
    "Let's do this 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "k = 3\n",
    "\n",
    "saves = []\n",
    "\n",
    "for iteration in range(1000):\n",
    "    centroids = rand_init(l_min, l_max, L_min, L_max, k) \n",
    "    distance_mat = get_distance_matrix(data_points, centroids, k)\n",
    "    clusters = clusterize(data_points, distance_mat, k)\n",
    "\n",
    "    centroids, clusters, score = repeat_until_good(score, centroids, data_points, k)\n",
    "    saves.append( (score, centroids) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take the best solution, thus the minimal score which means the least distance between centroids and data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_centroids = min(saves, key = lambda t: t[0])\n",
    "\n",
    "best_distance_mat = get_distance_matrix(data_points, best_centroids, k)\n",
    "best_clusters = clusterize(data_points, best_distance_mat, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.rand(k,3)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter( [x[0] for x in best_centroids], [y[1] for y in best_centroids], c= colors, marker = 's', s=100)\n",
    "for i in range(len(clusters)):\n",
    "    plt.scatter( [x[0] for x in best_clusters[i]], [y[1] for y in best_clusters[i]], c= [colors[i]]*len(best_clusters[i]), marker='.')\n",
    "    \n",
    "best_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
